{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data612 - Group Project 3 : Recommender System (Matrix Factorization)\n",
    "# date: 2019-06-25\n",
    "# by: Sang Yoon (Andy) Hwang, Santosh Cheruku, Anthony Munoz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to show which algorithm works the best for prediction - SVD, NMF and ALS (the lowest RMSE).\n",
    "We will use the algorithm that works the best to predict user ratings and recommend items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use 100k ratings dataset from movielens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import surprise\n",
    "from plotly.offline import init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "from surprise import Dataset\n",
    "from surprise import KNNBasic\n",
    "from surprise import Reader\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From https://grouplens.org/datasets/movielens/, ml-latest-small will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/wheremagichappens/an.dy/master/data612/ml-100k/ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to make our life a little bit easier, we will change the names of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['user','item','rating','timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      "user         100836 non-null int64\n",
      "item         100836 non-null int64\n",
      "rating       100836 non-null float64\n",
      "timestamp    100836 non-null int64\n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will find the best algorithm based on RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(df.rating.min(), df.rating.max()))\n",
    "data = Dataset.load_from_df(df[['user', 'item', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split data into 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.split(n_folds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=False)\n",
    "# result['test_rmse'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\surprise\\evaluate.py:66: UserWarning:\n",
      "\n",
      "The evaluate() method is deprecated. Please use model_selection.cross_validate() instead.\n",
      "\n",
      "C:\\Anaconda2\\lib\\site-packages\\surprise\\dataset.py:193: UserWarning:\n",
      "\n",
      "Using data.split() or using load_from_folds() without using a CV iterator is now deprecated. \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.8700\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.8763\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.8759\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 0.8769\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 0.8683\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.8735\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'rmse': [0.870026239585584,\n",
       "                             0.8762645843403616,\n",
       "                             0.8759016127337722,\n",
       "                             0.876948704668583,\n",
       "                             0.8682730515796463]})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = surprise.SVD()\n",
    "surprise.evaluate(algo, data, measures=['RMSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVDpp.\n",
      "\n",
      "------------\n",
      "Fold 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-ac9c9858f46b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0malgo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msurprise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVDpp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msurprise\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malgo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeasures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'RMSE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\surprise\\evaluate.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(algo, data, measures, with_dump, dump_dir, verbose)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;31m# train and test algorithm. Keep all rating predictions in a list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVDpp.fit\u001b[1;34m()\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[0mAlgoBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\surprise\\prediction_algorithms\\matrix_factorization.pyx\u001b[0m in \u001b[0;36msurprise.prediction_algorithms.matrix_factorization.SVDpp.sgd\u001b[1;34m()\u001b[0m\n\u001b[0;32m    445\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                 \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" processing epoch {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_ratings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m                 \u001b[1;31m# items rated by u. This is COSTLY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\surprise\\trainset.pyc\u001b[0m in \u001b[0;36mall_ratings\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_ratings\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miteritems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mur\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mu_ratings\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbuild_testset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#algo = surprise.SVDpp()\n",
    "#surprise.evaluate(algo, data, measures=['RMSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm NMF.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "RMSE: 0.9189\n",
      "------------\n",
      "Fold 2\n",
      "RMSE: 0.9225\n",
      "------------\n",
      "Fold 3\n",
      "RMSE: 0.9205\n",
      "------------\n",
      "Fold 4\n",
      "RMSE: 0.9206\n",
      "------------\n",
      "Fold 5\n",
      "RMSE: 0.9196\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.9204\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'rmse': [0.9189394197993441,\n",
       "                             0.9224562058196945,\n",
       "                             0.9204832703038095,\n",
       "                             0.9205707476542334,\n",
       "                             0.9195520865463978]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = surprise.NMF()\n",
    "surprise.evaluate(algo, data, measures=['RMSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaselineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm BaselineOnly.\n",
      "\n",
      "------------\n",
      "Fold 1\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8692\n",
      "------------\n",
      "Fold 2\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8744\n",
      "------------\n",
      "Fold 3\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8730\n",
      "------------\n",
      "Fold 4\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8753\n",
      "------------\n",
      "Fold 5\n",
      "Estimating biases using als...\n",
      "RMSE: 0.8697\n",
      "------------\n",
      "------------\n",
      "Mean RMSE: 0.8723\n",
      "------------\n",
      "------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CaseInsensitiveDefaultDict(list,\n",
       "                           {'rmse': [0.8691502017928444,\n",
       "                             0.8744398196375575,\n",
       "                             0.8729733142669314,\n",
       "                             0.8752502587316723,\n",
       "                             0.8696910682816448]})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = surprise.BaselineOnly()\n",
    "surprise.evaluate(algo, data, measures=['RMSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, BaselineOnly is the winner! It means we will use ALS. We will now test accuracy using training set on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BaselineOnly - ALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform train/test (80/20) split to create model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will configure ALS parameter for BaselineOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RMSE: 0.8634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8634267017490722"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsl_options = {'method': 'als'} #sgd - this case sgd has same output. Not too sure why.}\n",
    "algo = surprise.BaselineOnly(bsl_options=bsl_options)\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "predictions_als = algo.fit(trainset).test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions_als)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create DataFrame using prediction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>r_ui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>160</td>\n",
       "      <td>1375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.673909</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>480</td>\n",
       "      <td>27879</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.413758</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>274</td>\n",
       "      <td>60072</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.994028</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>965</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.902123</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>448</td>\n",
       "      <td>2380</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.503108</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid    iid  r_ui       est                     details\n",
       "0  160   1375   2.0  2.673909  {u'was_impossible': False}\n",
       "1  480  27879   4.0  3.413758  {u'was_impossible': False}\n",
       "2  274  60072   3.5  2.994028  {u'was_impossible': False}\n",
       "3   51    965   5.0  3.902123  {u'was_impossible': False}\n",
       "4  448   2380   2.0  2.503108  {u'was_impossible': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = pd.DataFrame(predictions_als)\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's select worst/top 10 prediction results on testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_10 = abs(prediction_df['r_ui'] - prediction_df['est']).sort_values(ascending=False).head(10)\n",
    "top_10 = abs(prediction_df['r_ui'] - prediction_df['est']).sort_values(ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worst 10 - it was way off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>r_ui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8602</th>\n",
       "      <td>256</td>\n",
       "      <td>5618</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.560000</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8920</th>\n",
       "      <td>573</td>\n",
       "      <td>3996</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.436986</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>413</td>\n",
       "      <td>1198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.724251</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19537</th>\n",
       "      <td>393</td>\n",
       "      <td>778</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.187817</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14547</th>\n",
       "      <td>239</td>\n",
       "      <td>48394</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.141754</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16609</th>\n",
       "      <td>594</td>\n",
       "      <td>799</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.123658</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12762</th>\n",
       "      <td>393</td>\n",
       "      <td>589</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.101478</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11468</th>\n",
       "      <td>393</td>\n",
       "      <td>74458</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.090345</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12213</th>\n",
       "      <td>419</td>\n",
       "      <td>1073</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.049540</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9637</th>\n",
       "      <td>111</td>\n",
       "      <td>593</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.018095</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid    iid  r_ui       est                     details\n",
       "8602   256   5618   0.5  4.560000  {u'was_impossible': False}\n",
       "8920   573   3996   0.5  4.436986  {u'was_impossible': False}\n",
       "4241   413   1198   1.0  4.724251  {u'was_impossible': False}\n",
       "19537  393    778   0.5  4.187817  {u'was_impossible': False}\n",
       "14547  239  48394   0.5  4.141754  {u'was_impossible': False}\n",
       "16609  594    799   0.5  4.123658  {u'was_impossible': False}\n",
       "12762  393    589   0.5  4.101478  {u'was_impossible': False}\n",
       "11468  393  74458   0.5  4.090345  {u'was_impossible': False}\n",
       "12213  419   1073   0.5  4.049540  {u'was_impossible': False}\n",
       "9637   111    593   0.5  4.018095  {u'was_impossible': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.iloc[worst_10.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best 10 - it predicted perfectly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>iid</th>\n",
       "      <th>r_ui</th>\n",
       "      <th>est</th>\n",
       "      <th>details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>122</td>\n",
       "      <td>858</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4873</th>\n",
       "      <td>169</td>\n",
       "      <td>318</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>122</td>\n",
       "      <td>1197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14794</th>\n",
       "      <td>523</td>\n",
       "      <td>318</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14777</th>\n",
       "      <td>171</td>\n",
       "      <td>318</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>560</td>\n",
       "      <td>4993</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.999874</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>20</td>\n",
       "      <td>4027</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.999840</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18361</th>\n",
       "      <td>599</td>\n",
       "      <td>2968</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.999806</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17530</th>\n",
       "      <td>610</td>\n",
       "      <td>91535</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.499727</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19174</th>\n",
       "      <td>503</td>\n",
       "      <td>3545</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000309</td>\n",
       "      <td>{u'was_impossible': False}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       uid    iid  r_ui       est                     details\n",
       "987    122    858   5.0  5.000000  {u'was_impossible': False}\n",
       "4873   169    318   5.0  5.000000  {u'was_impossible': False}\n",
       "7560   122   1197   5.0  5.000000  {u'was_impossible': False}\n",
       "14794  523    318   5.0  5.000000  {u'was_impossible': False}\n",
       "14777  171    318   5.0  5.000000  {u'was_impossible': False}\n",
       "6045   560   4993   4.0  3.999874  {u'was_impossible': False}\n",
       "5839    20   4027   4.0  3.999840  {u'was_impossible': False}\n",
       "18361  599   2968   3.0  2.999806  {u'was_impossible': False}\n",
       "17530  610  91535   3.5  3.499727  {u'was_impossible': False}\n",
       "19174  503   3545   3.0  3.000309  {u'was_impossible': False}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df.iloc[top_10.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use individual uid and iid to check individual prediciton result. Let's select one of the options in testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_10 = testset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 480        item: 27879      r_ui = 4.00   est = 3.41   {u'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# prediction using training set compare the results with testset\n",
    "uid = test_10[1][0]   # raw user id (as in the ratings file).\n",
    "iid = test_10[1][1]   # raw item id (as in the ratings file).\n",
    "\n",
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(uid, iid, r_ui=test_10[1][2], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then recommend top 5 movies by predicted ratings for any selected user. This time, I will merge item title data set with rating data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_names = pd.read_csv('https://raw.githubusercontent.com/wheremagichappens/an.dy/master/data612/ml-100k/movies.csv')\n",
    "item_names = item_names.iloc[:,[0,1]]\n",
    "item_names.columns = ['iid', 'title']\n",
    "prediction_df = prediction_df.merge(item_names, on = 'iid', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 5 movies for uid: 480 are iid: 356 - Forrest Gump (1994) with predicted ratings of 3.91209598816\n",
      "top 5 movies for uid: 480 are iid: 6016 - City of God (Cidade de Deus) (2002) with predicted ratings of 3.78791296156\n",
      "top 5 movies for uid: 480 are iid: 6874 - Kill Bill: Vol. 1 (2003) with predicted ratings of 3.77721872062\n",
      "top 5 movies for uid: 480 are iid: 1247 - Graduate, The (1967) with predicted ratings of 3.74832719893\n",
      "top 5 movies for uid: 480 are iid: 2324 - Life Is Beautiful (La Vita è bella) (1997) with predicted ratings of 3.74437344082\n"
     ]
    }
   ],
   "source": [
    "def recommender_user(uid):\n",
    "    top_5 = prediction_df[prediction_df.uid == uid].sort_values(by = 'est', ascending = False).head(5)\n",
    "    for i in range(len(top_5)):\n",
    "        print('top 5 movies for uid: {0} are iid: {1} - {2} with predicted ratings of {3}'.format(uid, top_5.iid.values[i], top_5.title.values[i], top_5.est.values[i]))\n",
    "\n",
    "recommender_user(uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE for SVD is only little bit higher than BaselineOnly's. Thus, we cannot really say one should always prefer ALS to SVD; depending on the case, one can still use SVD if that is more suitable for his/her own purpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
