---
title: "HW3"
author: "Team 1"
date: "October 25, 2020"
output: 
  prettydoc::html_pretty:
    theme: cayman
    toc: true
---

# 1. Data Exploration

The “Neighbourhood crime data” training data set contains 466 rows and 13 columns. The variables are thought to have a positive or negative effect on the crime rate being above median crime rate.Running a summary() function on the data set, we are able to get the mean, median, first and third quartile and the minimum and maximum values for each variable. We included a correlation plot and pairs plot to visualize the relationship among the variables.  

We explored the structure of the variables for both the training and evaluation data sets and finally observed how Target variable is affected by other factors. 


# 2. Data Preparation

Interestingly this data was much clean and there were no NA values identified in the data set. But going through the dataset description we could identify that some value though were numerical, but were representing certin classes and therefore should be converted into factors to help come up with right model. These included chas and rad.


# 3. Build Models

We focussed on building a logistic regression model since the target variable was binary variable with values limited to 0 or 1. Therefore, we used the glm package available within R to perform this. We build 3 LR models by applying the target variable against different dependent variables, and in one model we applied against all the dependent variables. Once we executed the models, we captured the AIC, null and residual deviance values in a table for easy representation of basic parameters of these models.  

# 4. Select Models

Out of the three models, the model that included all the parameters had least AIC value, as well as least residual deviance value. That clearly suggested that this model is better at learning.
We also generated the AIC for other models as well using stepAIC from MASS package.


# Appendix


# Library

```{r warning=FALSE, message=FALSE}
# load required packages
library(ggplot2)
library(dplyr)
#library(tidyr)
library(corrplot)
library(MASS)
library(caret)
library(RCurl)
library(tidyverse)
library(pROC)
library(kableExtra)
library(RCurl)
```

```{r import}
# Loading the data

git_dir <- 'https://raw.githubusercontent.com/Sizzlo/Data621/main'
train_df = read.csv(paste(git_dir, "/crime-training-data_modified.csv", sep=""))
test_df = read.csv(paste(git_dir, "/crime-evaluation-data_modified.csv", sep = ""))
head(train_df)
```

# Data Exploration & Preparation

## Summary of data
See a summary of each column in the train_df set
```{r train_dfing_data_summary}
# view a summary of all columns
summary(train_df)
```

## Structure of the data
```{r}
str(train_df)
str(test_df)
```



## NA check
```{r}
has_NA = names(which(sapply(train_df, anyNA)))
has_NA
```
There are no NAs observed


The summary() function for the training and testing data sets indicates that there are no missing values in the data. 
The response variable "target" is binary with 1 indicates crime rate is above median cirme rate and 0 indicates crime rate is not above median crime rate. 

Let's observe how the target variable is effected by other factors: </br>
1. The plot of "target" against "age" shows target equalling one (above median crime rate) increases as the proportion of owner-occupied units built prior to 1940 increaases; the boxplot further shows that a larger mean of proportions of owner-occupied units built prior to 1940 is assoicated with higher crime rate.</br>
2. Plots of crime rate against pupil-teacher ratio indicate higher crime rate "1" is associated with higher pupil-teacher ratio.

## Plotting
```{r}
par(mfrow=c(2,2))
# plot response variable "target" against predictor variable "age" 
plot(train_df$age,train_df$target)
boxplot(age ~ target, train_df )

# plot response variable "target" against predictor variable "ptratio"
plot(train_df$ptratio,train_df$target)
boxplot(ptratio ~ target, train_df)
```

## Corr analysis
```{r}
# Correlations 
cor_train <- cor(train_df,  use = "na.or.complete")
corrplot(cor_train)
```

```{r}
pairs(~ target + zn + indus
      + chas + nox + rm + age + dis + rad + tax + ptratio + lstat + medv, data = train_df)
```


## Converting to factors
```{r}
train_df$chas = as.factor(train_df$chas)
train_df$rad = as.factor(train_df$rad)
```

```{r warning=FALSE, message=FALSE}

model_metrics_df <- data.frame(Model=NA, AIC=NA, Null.Deviance=NA, Resid.Deviance=NA)


gather_metrics_func <- function(type, model_metrics_df, modelSummary) {
aic <- round(modelSummary$aic,4)
nullDeviance <- round(modelSummary$null.deviance, 4)
residDeviance <- round(modelSummary$df.residual, 4)

model_metrics_df <- rbind(model_metrics_df,c(type, aic, nullDeviance, residDeviance))
model_metrics_df <- na.omit(model_metrics_df)
return(model_metrics_df)
}
```


# Modeling


## Binary Logistic Regression
We are running Binary Logistic regression model with three 3 different set of parameters

### Modelling with Target ~ Age

```{r}
# preliminary exploration glm models
model1 <- glm(formula = target ~ age, family = binomial(), data = train_df)
summary(model1)
model_metrics_df <- gather_metrics_func('target ~ age', model_metrics_df, model1)
```


### Modelling with Target ~ ptratio

```{r}
# preliminary exploration glm models
model2 <- glm(formula = target ~ ptratio , family = binomial(), data = train_df)
summary(model2)
model_metrics_df <- gather_metrics_func('target ~ ptratio', model_metrics_df, model2)
```

### Modelling with Target ~ .(every other variable)
```{r}
all_preds = glm(target ~ ., family = binomial, data = train_df)
summary(all_preds)
model_metrics_df <- gather_metrics_func('target ~ .', model_metrics_df, all_preds)

```

## Comparing different models performance
```{r}

model_metrics_df %>% kbl() %>% kable_styling()

```


Looking at the table, we can identify on a high level that 3rd model that includes all 
the parameters is better suited. Therefore, let's come up with a confusion matrix for 3rd model that includes all the parameters.
```{r}

train_df$preds = ifelse(all_preds$fitted.values > 0.5, 1, 0)
# look at confusion matrix
cm = confusionMatrix(as_factor(train_df$preds), as_factor(train_df$target), positive = "1")
cm
```

## Using StepAIC 
Using the MASS package provided 'stepAIC' lets try to further refine the available models within it 
```{r}
step_all_preds = stepAIC(all_preds)
summary(step_all_preds)

train_df$preds = ifelse(step_all_preds$fitted.values > 0.5, 1, 0)
train_df$pred_proba = step_all_preds$fitted.values
# look at confusion matrix
cm = confusionMatrix(as_factor(train_df$preds), as_factor(train_df$target), positive = "1")
cm
```

```{r}
hist(step_all_preds$fitted.values, main= "Histogram of Predicted Probabilities", xlab="Predicted Probabilities")
```

# Plotting ROC 
```{r}
proc = roc(train_df$target, train_df$pred_proba)
plot(proc, asp=NA, legacy.axes=TRUE, print.auc=TRUE, xlab="Specificity")
```