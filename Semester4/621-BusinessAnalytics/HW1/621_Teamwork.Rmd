---
title: "HW1"
author: "Team 1"
date: "September 13, 2020"
output:
  pdf_document: default
  html_document: default
---

1.
The “moneyball” data set contains 2276 rows and 17 columns, including variables such as TARGET_WINS, TEAM_BATTING, TEAN_BASERUN, etc. Running a summary() function on the data set, we are able to get the mean, median, first and third quartile and the minimum and maximum values for each variable. We decided to use a scattered plot of base hit by batters (TEAM_BATTING_H) vs. number of wins (TARGET_WINS) for an overview of the relationship between wins and hits, the chart shows a
2.  Data Preparation 
We addressed issues with imperfect data before building models or performing statistical analysis. We observed that several variables have high numbers of NA or missing values. EAM_BATTING_HBP has the highest number of missing cases i.e., 2085 (~ 90%). Before deleting this variable, we fit a model with all data then compared to after the variable is removed. The second model appeared to be a better fit with smaller standard error, more variables became significant predictors. M
3. Build models.

First we started a model with the backward elimination process with the data.  In this process, we will be rejecting predictors with p-value greater than 0.05 with the backward elimination process. We will stop after all the predictors are less than 0.05.
The second model we decided to go with the stepwise selection which includes a semi-automated process of building a model by adding or removing variables based solely on the t-statistics of their estimated coefficients.  
For our third model we noticed one of the variables, TEAM_PITCHING_SO, have a p-value greater than 0.05 so we decided to investigate. When we removed the variable, TEAM_PITCHING_SO, and the R squared dropped slightly. 

4. Out of the three models we created, the second model created with stepwise selection is the best of the three. The Adjusted R squared is 0.4098 which explains approximately 41% of variation in Target Wins can be explained by our model. This f statistic tells us if there is a relationship between the dependent and independent variables we are testing. Generally, a large F indicates a stronger relationship and here we have 113.9. The normal quantile quantile plot for residuals displays an approximately straight line so the residuals are approximately normally distributed. The MSE is 743.6606. Using this model we were able to make predictions for our evaluation data.


```{r recho=FALSE}
# load required packages
library(ggplot2)
library(dplyr)
#library(tidyr)
library(corrplot)
library(MASS)
library(caret)
library(RCurl)
```

```{r import}
# Loading the data
git_dir <- 'https://raw.github.com/san123i/CUNY/master/Semester4/621-BusinessAnalytics/HW1/datasets'
train_df = read.csv(paste(git_dir, "/moneyball-training-data.csv", sep=""))
test_df = read.csv(paste(git_dir, "/moneyball-evaluation-data.csv", sep = ""))
```

# 1. Data Exploration

See a summary of each column in the train_dfing set
```{r train_dfing_data_summary}
# view a summary of all columns
summary(train_df)
```

```{r}
# Correlations 
cor_train = cor(train_df,  use = "na.or.complete")
corrplot(cor_train)
```

For types of hits, see a histogram of each
```{r hits_histograms}
par(mfrow=c(2,2))
hist(train_df$TEAM_BATTING_H,
     main = "hits histogram", xlab = "hits (season)",
     breaks = 20)
hist(train_df$TEAM_BATTING_2B,
     main = "doubles histogram", xlab = "doubles (season)",
     breaks = 20)
hist(train_df$TEAM_BATTING_3B,
     main = "triples histogram", xlab = "triples (season)",
     breaks = 20)
hist(train_df$TEAM_BATTING_HR,
     main = "homeruns histogram", xlab = "homeruns (season)",
     breaks = 20)
par(mfrow=c(1,1))
```

```{r}
pairs(~ TARGET_WINS + TEAM_BATTING_H + TEAM_BATTING_2B
      + TEAM_BATTING_3B + TEAM_BATTING_HR, data = train_df)
```
```{r}
# look at the structure of the variables
str(train_df)
str(eval)
```

```{r}
# lets observe how targets_win are effected by other factors
hist(train_df$TARGET_WINS,xlab="TARGET_WINS",main="")
# we have no TARGET_WINS from eval
# hist(eval$TARGET_WINS,xlab="TARGET_WINS",main="")
```



# 2. Data Preparation

1. We are told everything is standardized to match a 162 game season, so it is my preference to make TARGET_WINS a decimal of 162
```{r}
train_target_wins = train_df$TARGET_WINS
#train_df$TARGET_WINS = train_df$TARGET_WINS/162.
# TARGET_WINS now a decimal of games won in 162 game season
hist(train_df$TARGET_WINS,xlab="TARGET_WINS",main="")
str(train_df)
```

2. Assuming that everything that is NA can be filled by 0 based on the description of variables, create columns flagging if original values were NA (e.g. create TEAM_BATTING_HBP_NA column and value is 1 if TEAM_BATTING_HBP is NA and 0 otherwise meaning it wasn't NA and had a value. Do this for all columns)
```{r}
# 
has_NA = names(which(sapply(train_df, anyNA)))
for (col in has_NA)
{
   new_col = (paste(col,"_NA", sep=""))
   train_df[,new_col] = as.numeric(is.na(train_df[,col]))
   test_df[,new_col] = as.numeric(is.na(test_df[,col]))
}
train_df[is.na(train_df)] = 0
test_df[is.na(test_df)] = 0
```

# 3. Build Models
```{r}
# set seed for reproducibility
n_records = nrow(train_df)
set.seed(1)
```

# Model 1 - Backward Elimination Process

We will be rejecting predictors with p-value greater than 0.05 with the backward elimination process. We will stop after all the predictors are less than 0.05

```{r}
model <- lm(TARGET_WINS ~ TEAM_BATTING_H + TEAM_BATTING_2B + TEAM_BATTING_3B + TEAM_BATTING_HR + TEAM_BATTING_BB + TEAM_PITCHING_H + TEAM_PITCHING_HR + TEAM_PITCHING_BB + TEAM_FIELDING_E, data=train_df)
summary(train_df)

model <- update(model, .~. - TEAM_BATTING_BB, data=train_df)
summary(model)

model <- update(model, .~. - TEAM_PITCHING_HR, data=train_df)
summary(model)
```

```{r}
plot(fitted(model), resid(model))
hist(model$residuals)
qqnorm(resid(model))
qqline(resid(model))
```

```{r}
#predict the model on the eval
colnames(test_df)
#remove the predictors that have negative effect to the target wins

new_eval_model = subset(test_df, select=c(TEAM_BATTING_H, TEAM_BATTING_2B, TEAM_BATTING_3B, TEAM_BATTING_HR, TEAM_PITCHING_H, TEAM_PITCHING_BB, TEAM_FIELDING_E))
# Turn the NA values in 0
new_eval_model[is.na(new_eval_model)] = 0

# prediction model
prediction_model <- predict(model, newdata=new_eval_model)
prediction_model
```

# Model 2 - Stepwise Regression
```{r}
# Try stepwise regression as mentioned in http://www.sthda.com/english/articles/37-model-selection-essentials-in-r/154-stepwise-regression-essentials-in-r/
full_model = lm(TARGET_WINS ~ ., data=train_df)
step.model <- stepAIC(full_model, direction = "both", 
                      trace = FALSE)
summary(step.model)
```

```{r}
# Train model
train_control = trainControl(method = "cv", number = 10)
step_model = train(TARGET_WINS ~ ., data=train_df,
                   method = "lmStepAIC",
                   trControl = train_control,
                   trace=FALSE)
# Model accuracy
step_model$results

# Final model coefficients
step_model$finalModel

# Summary of model
summary(step_model$finalModel)
```

```{r}
model = step_model$finalModel
plot(fitted(model), resid(model))
hist(model$residuals, main='Rresiduals')
qqnorm(resid(model))
qqline(resid(model))

# Check MSE
mean(summary(model$residuals^2))
# 743.6606
```

# Model 3 - Try removing TEAM_PITCHING_SO
```{r}
# Train model without TEAM_PITCHING_SO since it has a relatively high p-value
train_control = trainControl(method = "cv", number = 10)
no_TPS = subset(train_df, select=-c(TEAM_PITCHING_SO))
step_model_noTPS = train(TARGET_WINS ~ ., data=no_TPS,
                   method = "lmStepAIC",
                   trControl = train_control,
                   trace=FALSE)
# Model accuracy
step_model_noTPS$results

# Final model coefficients
step_model_noTPS$finalModel

# Summary of model
summary(step_model_noTPS$finalModel)
```

```{r}
model_noTPS <- step_model_noTPS$finalModel
plot(fitted(model_noTPS), resid(model_noTPS))
hist(model_noTPS$residuals, main='No TPS residuals')
qqnorm(resid(model_noTPS))
qqline(resid(model_noTPS))
```

# Predictions on Evaluation Set

```{r}
# convert decimals of wins back to number of wins, rounded
test_preds = round(predict(model, newdata=test_df)) #*162
test_df$PRED_TARGET_WINS = test_preds
# write out evaluation data with predictions
write.csv(test_df, 'datasets/eval_with_preds.csv')
hist(test_preds, main = 'Test predictions')
hist(train_target_wins, main = 'Test predictions')
```